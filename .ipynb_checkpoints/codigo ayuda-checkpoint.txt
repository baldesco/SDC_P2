# Define a class to receive the characteristics of each line detection
class Line():
    def __init__(self):
        # was the line detected in the last iteration?
        self.detected = False  
        # x values of the last n fits of the line
        self.recent_xfitted = [] 
        #average x values of the fitted line over the last n iterations
        self.bestx = None     
        #polynomial coefficients averaged over the last n iterations
        self.best_fit = None  
        #polynomial coefficients for the most recent fit
        self.current_fit = [np.array([False])]  
        #radius of curvature of the line in some units
        self.radius_of_curvature = None 
        #distance in meters of vehicle center from the line
        self.line_base_pos = None 
        #difference in fit coefficients between last and new fits
        self.diffs = np.array([0,0,0], dtype='float') 
        #x values for detected line pixels
        self.allx = None  
        #y values for detected line pixels
        self.ally = None  

__________________________________________________________________________________________________________________

# Create an image to draw the lines on
warp_zero = np.zeros_like(warped).astype(np.uint8)
color_warp = np.dstack((warp_zero, warp_zero, warp_zero))

# Recast the x and y points into usable format for cv2.fillPoly()
pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])
pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])
pts = np.hstack((pts_left, pts_right))

# Draw the lane onto the warped blank image
cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))

# Warp the blank back to original image space using inverse perspective matrix (Minv)
newwarp = cv2.warpPerspective(color_warp, Minv, (image.shape[1], image.shape[0])) 
# Combine the result with the original image
result = cv2.addWeighted(undist, 1, newwarp, 0.3, 0)
plt.imshow(result)


_______________________________________________________________________________________________________________________

# MODIFY THIS FUNCTION TO GENERATE OUTPUT 
# THAT LOOKS LIKE THE IMAGE ABOVE
def corners_unwarp(img, nx, ny, mtx, dist):
    # Image size (inverted)
    img_size = (img.shape[1], img.shape[0])
    # Pass in your image into this function
    # Write code to do the following steps
    # 1) Undistort using mtx and dist
    img = cv2.undistort(img, mtx, dist, None, mtx)
    # 2) Convert to grayscale
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    # 3) Find the chessboard corners
    ret, corners = cv2.findChessboardCorners(gray, (nx,ny), None)
    # 4) If corners found: 
    if ret == True:
            # a) draw corners
        cv2.drawChessboardCorners(img, (nx,ny), corners, ret)
            # b) define 4 source points src = np.float32([[,],[,],[,],[,]])
                 #Note: you could pick any four of the detected corners 
                 # as long as those four corners define a rectangle
                 #One especially smart way to do this would be to use four well-chosen
                 # corners that were automatically detected during the undistortion steps
                 #We recommend using the automatic detection of corners in your code
        
        #Se buscan las cuatro esquinas externas de la imagen
        dims_dif = corners[:,0,0] - corners[:,0,1]
        dims_sum = corners[:,0,0] + corners[:,0,1]

        top_left = corners[np.argmin(dims_sum)]     # la suma de x,y debe ser pequeña porque es el punto más cercano a (0,0)
        bottom_right = corners[np.argmax(dims_sum)] # la suma de x,y debe ser grande porque es el punto más lejano a (0,0)
        top_right = corners[np.argmin(dims_dif)]    # pequeño y y grande x, por lo que (y - x) debe ser muy pequeño
        bottom_left = corners[np.argmax(dims_dif)]  # grande y y pequeño x, por lo que (y - x) debe ser grande
        
        src = np.float32([top_left,top_right,bottom_right,bottom_left])
            # c) define 4 destination points dst = np.float32([[,],[,],[,],[,]])
        margin = 120
        top_left = [margin, margin]
        bottom_right = [img.shape[1] - margin, img.shape[0] - margin]
        top_right = [margin, img.shape[0] - margin]
        bottom_left = [img.shape[1] - margin, margin]
        
        dst = np.float32([top_left,top_right,bottom_right,bottom_left])
            # d) use cv2.getPerspectiveTransform() to get M, the transform matrix
        M = cv2.getPerspectiveTransform(src, dst)
            # e) use cv2.warpPerspective() to warp your image to a top-down view
        warped = cv2.warpPerspective(img, M, img_size, flags=cv2.INTER_LINEAR)
    #delete the next two lines
#     M = None
#     warped = np.copy(img) 
        return warped, M



